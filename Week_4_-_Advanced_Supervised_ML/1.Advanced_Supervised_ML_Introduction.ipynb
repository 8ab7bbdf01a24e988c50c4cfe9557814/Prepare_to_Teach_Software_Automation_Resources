{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "902f62a8",
   "metadata": {},
   "source": [
    "# Advanced Supervised Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001ec67a",
   "metadata": {},
   "source": [
    "### K-nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b676a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "from utils_common import generate_data\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c0cfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random data set\n",
    "m = generate_data(0, 50, 0, 50, 150, 0.4)\n",
    "n = generate_data(0, 50, 0, 50, 150, 0.45)\n",
    "o = generate_data(30, 50, 30, 50, 10, 0.1)\n",
    "\n",
    "cols = [random.randint(0, 1) for _ in range(10)]\n",
    "radii = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea05144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbour Regression\n",
    "zoom = True\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "if not zoom:\n",
    "    plt.scatter(m[0], m[1], color='black')\n",
    "    plt.scatter(n[0], n[1], color='black')\n",
    "plt.scatter(o[0], o[1], color='black')\n",
    "plt.scatter(40, 40, color='red', label='Target Point')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565cbde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbour Classification\n",
    "zoom = True\n",
    "fig, ax = plt.subplots()\n",
    "if not zoom:\n",
    "    plt.scatter(m[0], m[1], color='black')\n",
    "    plt.scatter(n[0], n[1], color='yellow')\n",
    "else:\n",
    "    for radius in radii:\n",
    "        circle = Circle((40, 40), radius, color='blue', fill=False, linestyle='--')\n",
    "        ax.add_patch(circle)\n",
    "plt.scatter(o[0], o[1], c=cols)\n",
    "plt.scatter(40, 40, color='red', label='Target Point')\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9b81c1",
   "metadata": {},
   "source": [
    "### Neural Network Course Specifications\n",
    "\n",
    "<figure>\n",
    "    <center><img src=\"images\\NN_Course-Specs.png\" alt=\"Course Specs Neural Network image\" width=\"500\" />\n",
    "    <figcaption><p><em>Source: Page 29 of the Software Engineering Course Specifications</em></p>\n",
    "    </figcaption></center>\n",
    "</figure>\n",
    "\n",
    "Neural networks were designed to mimic the processing inside the human brain. They consist of a series of interconnected nodes (artificial neurones). Each neurone can accept a binary input signal and potentially output another signal to connected nodes.\n",
    "\n",
    "#### Training cycle\n",
    "\n",
    "Internal weightings and threshold values for each node are determined in the initial training cycle for each neural network. The system is exposed to a series of inputs with known responses. Linear regression with backward chaining is used to iteratively determine the set of unique values required for output. Regular exposure to the training cycle results in improved accuracy and pattern matching.\n",
    "\n",
    "#### Execution cycle\n",
    "\n",
    "In the diagram, signal strength between nodes with the strongest weightings are thicker representing a higher priority in determining the final output. The execution cycle follows the training cycle and utilises the internal values developed during the training cycle to determine the output.\n",
    "\n",
    "Page 29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9776f489",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "1. Root Node:\n",
    "The algorithm starts with the entire dataset as the root node. \n",
    "2. Splitting:\n",
    "At each node, the algorithm selects the feature and split value that best separates the data into subsets, minimizing the variance or impurity of the target variable in the subsets. \n",
    "3. Recursion:\n",
    "This process is repeated for each subset, creating new nodes and branches until a stopping criterion is met (e.g., maximum tree depth, minimum number of samples in a leaf). \n",
    "4. Leaf Nodes:\n",
    "The leaf nodes contain the predicted values, which are often the average or mean of the target variable values in the corresponding subset. \n",
    "5. Prediction:\n",
    "To predict the value for a new data point, you follow the path from the root node to a leaf node based on the data point's features, and the prediction is the value stored in that leaf. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
